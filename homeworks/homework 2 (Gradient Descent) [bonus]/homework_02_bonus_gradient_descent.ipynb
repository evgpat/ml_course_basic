{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание 2. Градиентный спуск"
      ],
      "metadata": {
        "id": "Ulur3C20JhXC"
      },
      "id": "Ulur3C20JhXC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV9pvgZJTYGj"
      },
      "source": [
        "Задание выполнил(а):\n",
        "\n",
        "    (впишите свои фамилию и имя)"
      ],
      "id": "lV9pvgZJTYGj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом ноутбуке мы решим задачу регрессии тремя способами:\n",
        "\n",
        "* с использованием точной (аналитической) формулы,\n",
        "\n",
        "* через готовую функцию из библиотеки scikit-learn,\n",
        "\n",
        "* с помощью собственной реализации метода градиентного спуска.\n",
        "\n",
        "На практике почти всегда применяются библиотечные реализации — они быстрее, надежнее и удобнее. Однако понимание того, как базовая задача машинного обучения решается «изнутри», чрезвычайно полезно. Это позволит:\n",
        "\n",
        "* лучше разбираться в ограничениях и особенностях методов;\n",
        "\n",
        "* осознанно выбирать и настраивать алгоритмы;\n",
        "\n",
        "* легче переходить к изучению более сложных моделей, включая нейронные сети, где градиентный спуск является основным инструментом оптимизации."
      ],
      "metadata": {
        "id": "jLY8mdgvekDw"
      },
      "id": "jLY8mdgvekDw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек, установка константных значений"
      ],
      "metadata": {
        "id": "g2dEfSqsLXWW"
      },
      "id": "g2dEfSqsLXWW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZP-DFujLqN_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import make_regression, fetch_california_housing\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "id": "BZP-DFujLqN_"
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 42"
      ],
      "metadata": {
        "id": "eFeAiX4BMOm7"
      },
      "id": "eFeAiX4BMOm7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Генерация данных"
      ],
      "metadata": {
        "id": "cq6TeDGvMKJx"
      },
      "id": "cq6TeDGvMKJx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы сами создадим синтетический датасет для того чтобы со всех сторон \"покрутить\" градиентный спуск.\n",
        "\n",
        "Функция ```make_regression``` из ```sklearn.datasets``` создает искусственный датасет для задачи линейной регрессии.\n",
        "\n",
        "Чтобы результаты генерации были воспроизводимыми, фиксируется зерно ```(RANDOM_STATE)```. Это гарантирует, что при каждом запуске будут получаться одинаковые данные. Не убирате и не меняйте его."
      ],
      "metadata": {
        "id": "vUkh9aXPa1iP"
      },
      "id": "vUkh9aXPa1iP"
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "X, y, _ = make_regression(n_samples=100000,              # число объектов\n",
        "                          n_features=9,                  # число признаков\n",
        "                          n_informative=8,               # число информативных признаков (остальные будут \"шумовыми\")\n",
        "                          noise=100,                     # уровень шума в данных\n",
        "                          coef=True,                     # значение True используется при генерации данных\n",
        "                          random_state=RANDOM_STATE)\n",
        "\n",
        "X = pd.DataFrame(data=X, columns=np.arange(0, X.shape[1]))\n",
        "X[9] = X[6] + X[7] + np.random.random()*0.01"
      ],
      "metadata": {
        "id": "kvGGY5QBMNiZ"
      },
      "id": "kvGGY5QBMNiZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHZ_SdUuu51k",
        "outputId": "162d0b31-0da7-4383-d674-a127e6533297"
      },
      "id": "QHZ_SdUuu51k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100000, 10), (100000,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpUNYEVMLqOB"
      },
      "source": [
        "Сгенерировали датасет из 100000 объектов и 10 признаков у каждого.\n",
        "\n",
        "Обучим модель линейной регрессии:\n",
        "\n",
        "$$\n",
        "a(x) = \\beta_1 d_{1} + \\beta_2 d_{2} + \\beta_3 d_{3} + \\beta_4 d_{4} + \\beta_5 d_{5} + \\beta_6 d_{6} + \\beta_7 d_{7} + \\beta_8 d_{8} + \\beta_9 d_{9} + \\beta_{10} d_{10} + \\beta_0\n",
        "$$\n",
        "\n",
        "Которая минимизирует MSE:\n",
        "\n",
        "$$\n",
        "Q(a(X), Y) = \\sum_i^{100000} (a(x_i) - y_i)^2\n",
        "$$"
      ],
      "id": "VpUNYEVMLqOB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Практика"
      ],
      "metadata": {
        "id": "m-vThqv4OaIL"
      },
      "id": "m-vThqv4OaIL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуем метод градиентного спуска для обучения линейной регрессии."
      ],
      "metadata": {
        "id": "cwclZC8bOmbG"
      },
      "id": "cwclZC8bOmbG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1 (10 баллов)"
      ],
      "metadata": {
        "id": "oeueMbAitu84"
      },
      "id": "oeueMbAitu84"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Напишите функцию, вычисляющую значение весов в линейной регрессии по точной (аналитически найденной) формуле:\n",
        "\n",
        "$$w = (X^TX)^{-1}X^Ty$$\n",
        "\n",
        "Комментарий: для поиска решения в векторном виде сначала необходимо добавить единичный столбец к матрице $X$.\n",
        "Допишите для этого код ниже"
      ],
      "metadata": {
        "id": "lm6_Ln0GoliG"
      },
      "id": "lm6_Ln0GoliG"
    },
    {
      "cell_type": "code",
      "source": [
        "def ols_solution(X, y):\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "    # ваш код здесь\n",
        "    w = np.linalg.inv(X.T @ X) @ X.T @ y\n"
      ],
      "metadata": {
        "id": "ZrVvpU9miOga"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZrVvpU9miOga"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2 (10 баллов)"
      ],
      "metadata": {
        "id": "1dzeu5eRtz6Z"
      },
      "id": "1dzeu5eRtz6Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заполните функцию для предсказания модели по формуле\n",
        "$$a(X)=Xw$$"
      ],
      "metadata": {
        "id": "AMBKhU7Zhaev"
      },
      "id": "AMBKhU7Zhaev"
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(X, w):\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "    # ваш код здесь\n",
        "    predict = X @ w\n",
        "    return predict\n"
      ],
      "metadata": {
        "id": "CI63O1eUhmyx"
      },
      "execution_count": null,
      "outputs": [],
      "id": "CI63O1eUhmyx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3 (10 баллов)"
      ],
      "metadata": {
        "id": "SUh-gdOovO_R"
      },
      "id": "SUh-gdOovO_R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6CUnbASLqOD"
      },
      "source": [
        "Обучите коэффициенты линейной регрессии с помощью библиотеки <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\"> **sklearn** </a>\n",
        "\n",
        "Отдельно выведите оценку свободного коэффициента  ($\\beta_0$ при $d_0 = 1$)."
      ],
      "id": "l6CUnbASLqOD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkEFpk44LqOE"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression()\n",
        "\n",
        "# ваш код здесь\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "print(\"Коэффициенты (веса):\", coefficients)\n",
        "print(\"Оценка свободного коэффициента (β0):\", intercept)"
      ],
      "id": "xkEFpk44LqOE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 4 (10 баллов)"
      ],
      "metadata": {
        "id": "f1snCMN3v4lK"
      },
      "id": "f1snCMN3v4lK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcDaHO-8LqOF"
      },
      "source": [
        "Напишите функцию для вычисления среднеквадратичной ошибки\n",
        "\n",
        "$MSE = \\frac{1}{m}||Xw - y||^2_2$.\n",
        "\n",
        "Здесь квадратичная ошибка записана в матричном виде, т.е. $X$ - матрица объект-признак, $w$ - вектор весов модели.\n",
        "*  $Xw$ - вектор предсказания модели\n",
        "*  $y$ - вектор правильных ответов,\n",
        "и квадратичная ошибка - это квадрат нормы разности вектора предсказания и вектора правильных ответов.\n",
        "\n",
        "Вычислить норму вектора в Python можно разными способами.  \n",
        "Для данного задания воспользуйтесь готовой функцией из библиотеку numpy - `numpy.linalg.norm`."
      ],
      "id": "AcDaHO-8LqOF"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y, theta):\n",
        "    m = len(y)\n",
        "    # ваш код здесь\n",
        "    cost = np.linalg.norm(prediction - y) ** 2 / m\n",
        "    return cost"
      ],
      "metadata": {
        "id": "j7L61byKzNgm"
      },
      "id": "j7L61byKzNgm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 5 (30 баллов)"
      ],
      "metadata": {
        "id": "k17ZEwP0zoIl"
      },
      "id": "k17ZEwP0zoIl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуем градиентный спуск по формуле\n",
        "\n",
        "$$w_{new} = w_{prev} - \\nabla_w Q(w_{prev})$$"
      ],
      "metadata": {
        "id": "Cj9DrXzZbOLi"
      },
      "id": "Cj9DrXzZbOLi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вычислим градиент MSE:\n",
        "$$\\nabla_w Q(w)=\\frac2m X^T(Xw-y).$$"
      ],
      "metadata": {
        "id": "nkcALpyjdIAT"
      },
      "id": "nkcALpyjdIAT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, реализуем метод градиентного спуска:\n",
        "\n",
        "*  первым шагом добавим к матрице `X` единичный столбец - это константный признак, равный 1 на всех объектах.  \n",
        "Он нужен, чтобы записать предсказание линейной регрессии в виде скалярного произведения и тем самым избавиться от знака суммы:\n",
        "$a(x)=w_0+w_1x_1+...+w_dx_d=w_1\\cdot 1+w_1x_1+...w_dx_d=(w,x)$  \n",
        "В python скалярное произведение можно записать так: `w@x`\n",
        "\n",
        "*  затем инициализируем случайным образом вектор весов `params`\n",
        "\n",
        "*  зададим пустой массив `cost_track`, в который будем записывать ошибку на каждой итерации\n",
        "\n",
        "*  наконец, в цикле по количеству эпох (итераций) будем обновлять веса по формуле градиентного спуска"
      ],
      "metadata": {
        "id": "2jus26KKsKTz"
      },
      "id": "2jus26KKsKTz"
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, learning_rate, iterations):\n",
        "\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X)) # добавляем к Х столбец из 1\n",
        "    params = ... # ваш код здесь\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    cost_track = ... # ваш код здесь\n",
        "\n",
        "    for i in range(iterations):\n",
        "        params = ... # ваш код здесь\n",
        "        cost_track[i] = ... # ваш код здесь\n",
        "\n",
        "    return cost_track, params"
      ],
      "metadata": {
        "id": "Yv43WbMnz9uv"
      },
      "id": "Yv43WbMnz9uv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 6 (10 баллов)"
      ],
      "metadata": {
        "id": "icj92uNx5h8I"
      },
      "id": "icj92uNx5h8I"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перепешите метод `gradient_descent`, используя критерий останова на ваш выбор"
      ],
      "metadata": {
        "id": "t9ZJIQ1Q5p8b"
      },
      "id": "t9ZJIQ1Q5p8b"
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, learning_rate, iterations, epsilon):\n",
        "  ..."
      ],
      "metadata": {
        "id": "nT8GzzH9514M"
      },
      "id": "nT8GzzH9514M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 7 (20 баллов)"
      ],
      "metadata": {
        "id": "IrRKGIwk07MA"
      },
      "id": "IrRKGIwk07MA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Обучите линейную регрессию тремя методами (по точной формуле, с помощью функции из библиотеки `sklearn` и с помощью GD) на данных для задачи регрессии ($X, y$). Для GD используйте `learning_rate = 0.01, iterations = 10000`, `epsilon = 0.001`.\n",
        "\n",
        "- С помощью каждого метода сделайте предсказание (на всех данных), вычислите качество предсказания r2 (`from sklearn.metrics import r2_score`). Для получения предсказания использоуйте функцию `predict`.\n"
      ],
      "metadata": {
        "id": "lkUYleyH1AXl"
      },
      "id": "lkUYleyH1AXl"
    },
    {
      "cell_type": "code",
      "source": [
        "# **План**\n",
        "\n",
        "# 1 - находим веса одним из методов\n",
        "\n",
        "# 2 - применяем функцию prediction для получения предсказаний с найденными весами\n",
        "\n",
        "# 3 - вычисляем значение метрики r2"
      ],
      "metadata": {
        "id": "916V-sOr0_Zy"
      },
      "id": "916V-sOr0_Zy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}